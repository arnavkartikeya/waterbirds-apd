{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import os\n",
    "from pathlib import Path\n",
    "from typing import Callable, Optional\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as T\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "from wilds import get_dataset\n",
    "\n",
    "from models import WaterbirdResNet18, SPDTwoLayerFC\n",
    "from spd.run_spd import get_lr_schedule_fn, get_lr_with_warmup\n",
    "from spd.hooks import HookedRootModule\n",
    "from spd.log import logger\n",
    "from spd.models.base import SPDModel\n",
    "from spd.module_utils import (\n",
    "    get_nested_module_attr,\n",
    "    collect_nested_module_attrs,\n",
    ")\n",
    "from spd.types import Probability\n",
    "from spd.utils import set_seed\n",
    "from train_resnet import WaterbirdsSubset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1246640/3389912760.py:28: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  resnet_checkpoint = torch.load(resnet_ckpt_path, map_location=\"cpu\")\n",
      "/tmp/ipykernel_1246640/3389912760.py:44: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  spd_state_dict = torch.load(spd_ckpt_path, map_location=\"cpu\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CombinedWaterbirdModel(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (4): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (5): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (6): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (7): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (8): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  )\n",
       "  (spd_model): SPDTwoLayerFC(\n",
       "    (fc1): LinearComponent(\n",
       "      (hook_pre): HookPoint()\n",
       "      (hook_component_acts): HookPoint()\n",
       "      (hook_post): HookPoint()\n",
       "    )\n",
       "    (fc2): LinearComponent(\n",
       "      (hook_pre): HookPoint()\n",
       "      (hook_component_acts): HookPoint()\n",
       "      (hook_post): HookPoint()\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# Define a combined model that uses the pretrained ResNet backbone \n",
    "# but replaces the FC layers with your SPD module\n",
    "class CombinedWaterbirdModel(nn.Module):\n",
    "    def __init__(self, resnet_model, spd_model):\n",
    "        super().__init__()\n",
    "        # Use only the feature extractor part of the ResNet18 model\n",
    "        self.features = resnet_model.features\n",
    "        # Use the SPD model for the fully connected part\n",
    "        self.spd_model = spd_model\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Extract features using ResNet backbone\n",
    "        feats = self.features(x)               # [B, 512, 1, 1]\n",
    "        feats = feats.flatten(start_dim=1)     # [B, 512]\n",
    "        \n",
    "        # Pass features to SPD module\n",
    "        out = self.spd_model(feats)\n",
    "        return out\n",
    "\n",
    "# 1. Load the pretrained ResNet model\n",
    "resnet_model = WaterbirdResNet18(num_classes=2, hidden_dim=512)\n",
    "resnet_ckpt_path = \"checkpoints/waterbird_resnet18_best.pth\"\n",
    "\n",
    "# The file showed the checkpoint has a different structure - it's a dictionary\n",
    "resnet_checkpoint = torch.load(resnet_ckpt_path, map_location=\"cpu\")\n",
    "resnet_model.load_state_dict(resnet_checkpoint['model_state_dict'])\n",
    "resnet_model.eval()\n",
    "\n",
    "# 2. Load the SPD model \n",
    "spd_model = SPDTwoLayerFC(\n",
    "    in_features=512,\n",
    "    hidden_dim=512,\n",
    "    num_classes=2,\n",
    "    C=40,\n",
    "    m_fc1=16,\n",
    "    m_fc2=16,\n",
    ")\n",
    "\n",
    "# Load SPD state dict\n",
    "spd_ckpt_path = \"waterbird_spd_out/waterbird_spd_final.pth\"\n",
    "spd_state_dict = torch.load(spd_ckpt_path, map_location=\"cpu\")\n",
    "spd_model.load_state_dict(spd_state_dict)\n",
    "spd_model.eval()\n",
    "\n",
    "# 3. Create the combined model\n",
    "combined_model = CombinedWaterbirdModel(resnet_model, spd_model)\n",
    "combined_model.eval()\n",
    "\n",
    "# To use for inference:\n",
    "# with torch.no_grad():\n",
    "#     output = combined_model(input_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total dataset size: 11788\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1246640/3955101530.py:38: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  resnet_checkpoint = torch.load(resnet_ckpt_path, map_location=\"cpu\")\n",
      "/tmp/ipykernel_1246640/3955101530.py:52: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  spd_state_dict = torch.load(spd_ckpt_path, map_location=\"cpu\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating combined model on 1000 validation samples...\n",
      "Combined model accuracy on validation set: 71.00%\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.transforms as T\n",
    "from wilds import get_dataset\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# First, setup validation dataset\n",
    "waterbird_dataset = get_dataset(dataset=\"waterbirds\", download=False)\n",
    "dataset_size = len(waterbird_dataset)\n",
    "print(f\"Total dataset size: {dataset_size}\")\n",
    "\n",
    "# Get indices\n",
    "all_indices = np.arange(dataset_size)\n",
    "np.random.shuffle(all_indices)\n",
    "train_indices = all_indices[:2000].tolist()\n",
    "val_indices = all_indices[2000:3000].tolist()  # Taking 1000 samples after the 2000th index\n",
    "\n",
    "# Setup validation transform\n",
    "val_transform = T.Compose([\n",
    "    T.Resize((224, 224)),\n",
    "    T.ToTensor()\n",
    "])\n",
    "\n",
    "# Create validation subset\n",
    "val_subset = WaterbirdsSubset(\n",
    "    waterbird_dataset, \n",
    "    indices=val_indices,\n",
    "    transform=val_transform\n",
    ")\n",
    "val_loader = DataLoader(val_subset, batch_size=32, shuffle=False)\n",
    "\n",
    "# Load the combined model\n",
    "# 1. Load ResNet\n",
    "resnet_model = WaterbirdResNet18(num_classes=2, hidden_dim=512)\n",
    "resnet_ckpt_path = \"checkpoints/waterbird_resnet18_best.pth\"\n",
    "resnet_checkpoint = torch.load(resnet_ckpt_path, map_location=\"cpu\")\n",
    "resnet_model.load_state_dict(resnet_checkpoint['model_state_dict'])\n",
    "resnet_model.eval()\n",
    "\n",
    "# 2. Load SPD model\n",
    "spd_model = SPDTwoLayerFC(\n",
    "    in_features=512,\n",
    "    hidden_dim=512,\n",
    "    num_classes=2,\n",
    "    C=40,\n",
    "    m_fc1=16,\n",
    "    m_fc2=16,\n",
    ")\n",
    "spd_ckpt_path = \"waterbird_spd_out/waterbird_spd_final.pth\"\n",
    "spd_state_dict = torch.load(spd_ckpt_path, map_location=\"cpu\")\n",
    "spd_model.load_state_dict(spd_state_dict)\n",
    "spd_model.eval()\n",
    "\n",
    "# 3. Create combined model\n",
    "class CombinedWaterbirdModel(nn.Module):\n",
    "    def __init__(self, resnet_model, spd_model):\n",
    "        super().__init__()\n",
    "        self.features = resnet_model.features\n",
    "        self.spd_model = spd_model\n",
    "        \n",
    "    def forward(self, x):\n",
    "        feats = self.features(x)\n",
    "        feats = feats.flatten(start_dim=1)\n",
    "        out = self.spd_model(feats)\n",
    "        return out\n",
    "\n",
    "# Create the combined model and move to GPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "combined_model = CombinedWaterbirdModel(resnet_model, spd_model).to(device)\n",
    "combined_model.eval()\n",
    "\n",
    "# Evaluate on validation set\n",
    "correct = 0\n",
    "total = 0\n",
    "metadata_correct = {}  # For analysis by metadata\n",
    "metadata_total = {}\n",
    "\n",
    "print(f\"Evaluating combined model on {len(val_indices)} validation samples...\")\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, labels, metadata in val_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = combined_model(inputs)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        \n",
    "        # Update overall stats\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = 100 * correct / total\n",
    "print(f\"Combined model accuracy on validation set: {accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Landbirds on land: 6220 samples\n",
      "Waterbirds on water: 1832 samples\n",
      "Landbirds on water: 2905 samples\n",
      "Waterbirds on land: 831 samples\n",
      "\n",
      "Evaluating original ResNet model:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 195/195 [00:26<00:00,  7.33it/s]\n",
      "100%|██████████| 58/58 [00:07<00:00,  7.49it/s]\n",
      "100%|██████████| 91/91 [00:12<00:00,  7.14it/s]\n",
      "100%|██████████| 26/26 [00:03<00:00,  7.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Landbirds on land: 98.26%\n",
      "Waterbirds on water: 86.08%\n",
      "Landbirds on water: 25.44%\n",
      "Waterbirds on land: 4.93%\n",
      "\n",
      "Evaluating combined model:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 195/195 [00:26<00:00,  7.34it/s]\n",
      "100%|██████████| 58/58 [00:07<00:00,  7.41it/s]\n",
      "100%|██████████| 91/91 [00:12<00:00,  7.43it/s]\n",
      "100%|██████████| 26/26 [00:03<00:00,  7.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Landbirds on land: 98.31%\n",
      "Waterbirds on water: 85.81%\n",
      "Landbirds on water: 25.99%\n",
      "Waterbirds on land: 4.81%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from wilds import get_dataset\n",
    "import torchvision.transforms as T\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Get the dataset\n",
    "dataset = get_dataset(dataset=\"waterbirds\", download=False)\n",
    "\n",
    "# Create transform\n",
    "transform = T.Compose([\n",
    "    T.Resize((224, 224)),\n",
    "    T.ToTensor()\n",
    "])\n",
    "\n",
    "# Define a function to get samples by group\n",
    "def get_group_indices(dataset, bird_type, background):\n",
    "    \"\"\"\n",
    "    Get indices of samples where:\n",
    "    - bird_type: 0 for landbird, 1 for waterbird\n",
    "    - background: 0 for land, 1 for water\n",
    "    \"\"\"\n",
    "    indices = []\n",
    "    for i in range(len(dataset)):\n",
    "        x, y, metadata = dataset[i]\n",
    "        # y is the bird type, metadata[1] is the background type\n",
    "        if y == bird_type and metadata[0] == background:\n",
    "            indices.append(i)\n",
    "    return indices\n",
    "\n",
    "# Get indices for each group\n",
    "landbird_land = get_group_indices(dataset, 0, 0)  # Majority group\n",
    "waterbird_water = get_group_indices(dataset, 1, 1)  # Majority group\n",
    "landbird_water = get_group_indices(dataset, 0, 1)  # Minority group\n",
    "waterbird_land = get_group_indices(dataset, 1, 0)  # Minority group\n",
    "\n",
    "print(f\"Landbirds on land: {len(landbird_land)} samples\")\n",
    "print(f\"Waterbirds on water: {len(waterbird_water)} samples\")\n",
    "print(f\"Landbirds on water: {len(landbird_water)} samples\")  # This should be smaller\n",
    "print(f\"Waterbirds on land: {len(waterbird_land)} samples\")  # This should be smaller\n",
    "\n",
    "# Function to evaluate model on a specific group\n",
    "def evaluate_group(model, dataset, indices, transform, device, batch_size=32):\n",
    "    subset = Subset(dataset, indices)\n",
    "    \n",
    "    # Create a custom dataset that applies the transform\n",
    "    class TransformSubset:\n",
    "        def __init__(self, subset, transform):\n",
    "            self.subset = subset\n",
    "            self.transform = transform\n",
    "            \n",
    "        def __len__(self):\n",
    "            return len(self.subset)\n",
    "            \n",
    "        def __getitem__(self, idx):\n",
    "            x, y, metadata = self.subset[idx]\n",
    "            if self.transform:\n",
    "                x = self.transform(x)\n",
    "            return x, y, metadata\n",
    "    \n",
    "    # Create the loader\n",
    "    loader = DataLoader(\n",
    "        TransformSubset(subset, transform),\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False\n",
    "    )\n",
    "    \n",
    "    # Evaluate\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels, metadata in tqdm(loader):\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    \n",
    "    accuracy = 100 * correct / total if total > 0 else 0\n",
    "    return accuracy\n",
    "\n",
    "# Now you can evaluate both your models on each group\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Evaluate original ResNet model\n",
    "print(\"\\nEvaluating original ResNet model:\")\n",
    "resnet_model = resnet_model.to(device)\n",
    "landbird_land_acc = evaluate_group(resnet_model, dataset, landbird_land, transform, device)\n",
    "waterbird_water_acc = evaluate_group(resnet_model, dataset, waterbird_water, transform, device)\n",
    "landbird_water_acc = evaluate_group(resnet_model, dataset, landbird_water, transform, device)\n",
    "waterbird_land_acc = evaluate_group(resnet_model, dataset, waterbird_land, transform, device)\n",
    "\n",
    "print(f\"Landbirds on land: {landbird_land_acc:.2f}%\")\n",
    "print(f\"Waterbirds on water: {waterbird_water_acc:.2f}%\")\n",
    "print(f\"Landbirds on water: {landbird_water_acc:.2f}%\")\n",
    "print(f\"Waterbirds on land: {waterbird_land_acc:.2f}%\")\n",
    "\n",
    "# Evaluate combined model\n",
    "print(\"\\nEvaluating combined model:\")\n",
    "combined_model = combined_model.to(device)\n",
    "landbird_land_acc = evaluate_group(combined_model, dataset, landbird_land, transform, device)\n",
    "waterbird_water_acc = evaluate_group(combined_model, dataset, waterbird_water, transform, device)\n",
    "landbird_water_acc = evaluate_group(combined_model, dataset, landbird_water, transform, device)\n",
    "waterbird_land_acc = evaluate_group(combined_model, dataset, waterbird_land, transform, device)\n",
    "\n",
    "print(f\"Landbirds on land: {landbird_land_acc:.2f}%\")\n",
    "print(f\"Waterbirds on water: {waterbird_water_acc:.2f}%\")\n",
    "print(f\"Landbirds on water: {landbird_water_acc:.2f}%\")\n",
    "print(f\"Waterbirds on land: {waterbird_land_acc:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating combined model on 1000 validation samples, ablating circuit #0...\n",
      "Ablating circuit #0 => Accuracy on validation set: 71.10%\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.transforms as T\n",
    "from wilds import get_dataset\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# --- Same data-loading code as before ---\n",
    "# (omitted for brevity)\n",
    "\n",
    "# --- Same checkpoint loading for resnet_model and spd_model ---\n",
    "# (omitted for brevity)\n",
    "\n",
    "# Evaluate on validation set, but ablate circuit #0\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "print(f\"Evaluating combined model on {len(val_indices)} validation samples, \"\n",
    "      \"ablating circuit #0...\")\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "resnet_model.to(device).eval()\n",
    "spd_model.to(device).eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, labels, metadata in val_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        # 1) Extract features from ResNet trunk\n",
    "        feats = resnet_model.features(inputs)\n",
    "        feats = feats.flatten(start_dim=1)  # shape [batch_size, 512]\n",
    "\n",
    "        # 2) Build the topk_mask that ablates circuit #0\n",
    "        batch_size = feats.size(0)\n",
    "        topk_mask = torch.ones((batch_size, spd_model.C), dtype=torch.bool, device=device)\n",
    "        topk_mask[:, 0] = False  # Turn off circuit #0 for every example\n",
    "\n",
    "        # 3) Forward pass through SPD with ablation\n",
    "        outputs = spd_model(feats, topk_mask=topk_mask)\n",
    "\n",
    "        # 4) Compute predictions\n",
    "        _, predicted = torch.max(outputs, dim=1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "accuracy = 100 * correct / total\n",
    "print(f\"Ablating circuit #0 => Accuracy on validation set: {accuracy:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Landbirds on land: 6220 samples\n",
      "Waterbirds on water: 1832 samples\n",
      "Landbirds on water: 2905 samples\n",
      "Waterbirds on land: 831 samples\n",
      "\n",
      "Evaluating combined model (no ablation):\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 195/195 [00:26<00:00,  7.30it/s]\n",
      "100%|██████████| 58/58 [00:07<00:00,  7.53it/s]\n",
      "100%|██████████| 91/91 [00:12<00:00,  7.39it/s]\n",
      "100%|██████████| 26/26 [00:03<00:00,  7.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Landbirds on land: 98.31%\n",
      "Waterbirds on water: 85.81%\n",
      "Landbirds on water: 25.99%\n",
      "Waterbirds on land: 4.81%\n",
      "\n",
      "Evaluating combined model with circuit(s) [0] ablated:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 195/195 [00:26<00:00,  7.32it/s]\n",
      "100%|██████████| 58/58 [00:07<00:00,  7.57it/s]\n",
      "100%|██████████| 91/91 [00:12<00:00,  7.53it/s]\n",
      "100%|██████████| 26/26 [00:03<00:00,  7.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Landbirds on land: 98.50%\n",
      "Waterbirds on water: 84.83%\n",
      "Landbirds on water: 27.33%\n",
      "Waterbirds on land: 4.45%\n",
      "\n",
      "Accuracy differences (ablated - normal):\n",
      "Landbirds on land: 0.19%\n",
      "Waterbirds on water: -0.98%\n",
      "Landbirds on water: 1.34%\n",
      "Waterbirds on land: -0.36%\n",
      "\n",
      "Evaluating combined model with circuit(s) [0, 1, 2] ablated:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 195/195 [00:27<00:00,  7.17it/s]\n",
      "100%|██████████| 58/58 [00:07<00:00,  7.55it/s]\n",
      "100%|██████████| 91/91 [00:12<00:00,  7.50it/s]\n",
      "100%|██████████| 26/26 [00:03<00:00,  7.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Landbirds on land: 98.49%\n",
      "Waterbirds on water: 84.99%\n",
      "Landbirds on water: 27.26%\n",
      "Waterbirds on land: 4.45%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from wilds import get_dataset\n",
    "import torchvision.transforms as T\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Get the dataset\n",
    "dataset = get_dataset(dataset=\"waterbirds\", download=False)\n",
    "\n",
    "# Create transform\n",
    "transform = T.Compose([\n",
    "    T.Resize((224, 224)),\n",
    "    T.ToTensor()\n",
    "])\n",
    "\n",
    "# Define a function to get samples by group\n",
    "def get_group_indices(dataset, bird_type, background):\n",
    "    \"\"\"\n",
    "    Get indices of samples where:\n",
    "    - bird_type: 0 for landbird, 1 for waterbird\n",
    "    - background: 0 for land, 1 for water\n",
    "    \"\"\"\n",
    "    indices = []\n",
    "    for i in range(len(dataset)):\n",
    "        x, y, metadata = dataset[i]\n",
    "        # y is the bird type, metadata[0] is the background type\n",
    "        if y == bird_type and metadata[0] == background:\n",
    "            indices.append(i)\n",
    "    return indices\n",
    "\n",
    "# Get indices for each group\n",
    "landbird_land = get_group_indices(dataset, 0, 0)  # Majority group\n",
    "waterbird_water = get_group_indices(dataset, 1, 1)  # Majority group\n",
    "landbird_water = get_group_indices(dataset, 0, 1)  # Minority group\n",
    "waterbird_land = get_group_indices(dataset, 1, 0)  # Minority group\n",
    "\n",
    "print(f\"Landbirds on land: {len(landbird_land)} samples\")\n",
    "print(f\"Waterbirds on water: {len(waterbird_water)} samples\")\n",
    "print(f\"Landbirds on water: {len(landbird_water)} samples\")\n",
    "print(f\"Waterbirds on land: {len(waterbird_land)} samples\")\n",
    "\n",
    "# Modified function to evaluate model on a specific group with optional circuit ablation\n",
    "def evaluate_group(resnet_model, spd_model, dataset, indices, transform, device, \n",
    "                  batch_size=32, ablate_circuits=None):\n",
    "    \"\"\"\n",
    "    Evaluate model on a specific group with optional circuit ablation\n",
    "    \n",
    "    Args:\n",
    "        resnet_model: Feature extractor model\n",
    "        spd_model: SPD model with circuits\n",
    "        dataset: Dataset object\n",
    "        indices: Indices to evaluate on\n",
    "        transform: Image transform\n",
    "        device: Device to run on\n",
    "        batch_size: Batch size for evaluation\n",
    "        ablate_circuits: List of circuit indices to ablate (set to None for no ablation)\n",
    "    \n",
    "    Returns:\n",
    "        accuracy: Accuracy on the evaluated group\n",
    "    \"\"\"\n",
    "    subset = Subset(dataset, indices)\n",
    "    \n",
    "    # Create a custom dataset that applies the transform\n",
    "    class TransformSubset:\n",
    "        def __init__(self, subset, transform):\n",
    "            self.subset = subset\n",
    "            self.transform = transform\n",
    "            \n",
    "        def __len__(self):\n",
    "            return len(self.subset)\n",
    "            \n",
    "        def __getitem__(self, idx):\n",
    "            x, y, metadata = self.subset[idx]\n",
    "            if self.transform:\n",
    "                x = self.transform(x)\n",
    "            return x, y, metadata\n",
    "    \n",
    "    # Create the loader\n",
    "    loader = DataLoader(\n",
    "        TransformSubset(subset, transform),\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False\n",
    "    )\n",
    "    \n",
    "    # Evaluate\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    resnet_model.eval()\n",
    "    spd_model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for inputs, labels, metadata in tqdm(loader):\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            \n",
    "            # Extract features using ResNet\n",
    "            feats = resnet_model.features(inputs)\n",
    "            feats = feats.flatten(start_dim=1)  # [B, 512]\n",
    "            \n",
    "            # Create ablation mask if needed\n",
    "            if ablate_circuits is not None and len(ablate_circuits) > 0:\n",
    "                batch_size = feats.size(0)\n",
    "                topk_mask = torch.ones((batch_size, spd_model.C), dtype=torch.bool, device=device)\n",
    "                for circuit_idx in ablate_circuits:\n",
    "                    topk_mask[:, circuit_idx] = False  # Turn off specified circuits\n",
    "                \n",
    "                # Forward pass through SPD with ablation\n",
    "                outputs = spd_model(feats, topk_mask=topk_mask)\n",
    "            else:\n",
    "                # Normal forward pass through SPD without ablation\n",
    "                outputs = spd_model(feats)\n",
    "            \n",
    "            # Compute predictions\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    \n",
    "    accuracy = 100 * correct / total if total > 0 else 0\n",
    "    return accuracy\n",
    "\n",
    "# Now you can evaluate both models on each group\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Load models (assuming you've already loaded them before)\n",
    "# resnet_model = ... (your ResNet model)\n",
    "# spd_model = ... (your SPD model)\n",
    "\n",
    "# First, evaluate the standard model performance (without ablation)\n",
    "print(\"\\nEvaluating combined model (no ablation):\")\n",
    "landbird_land_acc = evaluate_group(resnet_model, spd_model, dataset, landbird_land, transform, device)\n",
    "waterbird_water_acc = evaluate_group(resnet_model, spd_model, dataset, waterbird_water, transform, device)\n",
    "landbird_water_acc = evaluate_group(resnet_model, spd_model, dataset, landbird_water, transform, device)\n",
    "waterbird_land_acc = evaluate_group(resnet_model, spd_model, dataset, waterbird_land, transform, device)\n",
    "\n",
    "print(f\"Landbirds on land: {landbird_land_acc:.2f}%\")\n",
    "print(f\"Waterbirds on water: {waterbird_water_acc:.2f}%\")\n",
    "print(f\"Landbirds on water: {landbird_water_acc:.2f}%\")\n",
    "print(f\"Waterbirds on land: {waterbird_land_acc:.2f}%\")\n",
    "\n",
    "# Now evaluate with circuit #0 ablated\n",
    "ablate_circuits = [0]  # Ablate circuit #0\n",
    "print(f\"\\nEvaluating combined model with circuit(s) {ablate_circuits} ablated:\")\n",
    "landbird_land_acc_abl = evaluate_group(resnet_model, spd_model, dataset, landbird_land, transform, device, ablate_circuits=ablate_circuits)\n",
    "waterbird_water_acc_abl = evaluate_group(resnet_model, spd_model, dataset, waterbird_water, transform, device, ablate_circuits=ablate_circuits)\n",
    "landbird_water_acc_abl = evaluate_group(resnet_model, spd_model, dataset, landbird_water, transform, device, ablate_circuits=ablate_circuits)\n",
    "waterbird_land_acc_abl = evaluate_group(resnet_model, spd_model, dataset, waterbird_land, transform, device, ablate_circuits=ablate_circuits)\n",
    "\n",
    "print(f\"Landbirds on land: {landbird_land_acc_abl:.2f}%\")\n",
    "print(f\"Waterbirds on water: {waterbird_water_acc_abl:.2f}%\")\n",
    "print(f\"Landbirds on water: {landbird_water_acc_abl:.2f}%\")\n",
    "print(f\"Waterbirds on land: {waterbird_land_acc_abl:.2f}%\")\n",
    "\n",
    "# Print the differences\n",
    "print(\"\\nAccuracy differences (ablated - normal):\")\n",
    "print(f\"Landbirds on land: {landbird_land_acc_abl - landbird_land_acc:.2f}%\")\n",
    "print(f\"Waterbirds on water: {waterbird_water_acc_abl - waterbird_water_acc:.2f}%\")\n",
    "print(f\"Landbirds on water: {landbird_water_acc_abl - landbird_water_acc:.2f}%\")\n",
    "print(f\"Waterbirds on land: {waterbird_land_acc_abl - waterbird_land_acc:.2f}%\")\n",
    "\n",
    "# You can easily test ablating multiple circuits\n",
    "ablate_circuits = [0, 1, 2]  # Ablate circuits 0, 1, and 2\n",
    "print(f\"\\nEvaluating combined model with circuit(s) {ablate_circuits} ablated:\")\n",
    "landbird_land_acc_multi = evaluate_group(resnet_model, spd_model, dataset, landbird_land, transform, device, ablate_circuits=ablate_circuits)\n",
    "waterbird_water_acc_multi = evaluate_group(resnet_model, spd_model, dataset, waterbird_water, transform, device, ablate_circuits=ablate_circuits)\n",
    "landbird_water_acc_multi = evaluate_group(resnet_model, spd_model, dataset, landbird_water, transform, device, ablate_circuits=ablate_circuits)\n",
    "waterbird_land_acc_multi = evaluate_group(resnet_model, spd_model, dataset, waterbird_land, transform, device, ablate_circuits=ablate_circuits)\n",
    "\n",
    "print(f\"Landbirds on land: {landbird_land_acc_multi:.2f}%\")\n",
    "print(f\"Waterbirds on water: {waterbird_water_acc_multi:.2f}%\")\n",
    "print(f\"Landbirds on water: {landbird_water_acc_multi:.2f}%\")\n",
    "print(f\"Waterbirds on land: {waterbird_land_acc_multi:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
